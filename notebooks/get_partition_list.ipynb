{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "576410b5-873a-42ef-b3c2-7887dcf36cba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.dropdown('src_type', 'sqlserver', ['sqlserver', 'postgresql', 'delta'], '01 Source Type')\n",
    "dbutils.widgets.text('src_catalog', '', '02 Source Catalog')\n",
    "dbutils.widgets.text('src_schema', '', '03 Source Schema')\n",
    "dbutils.widgets.text('src_table', '', '04 Source Table')\n",
    "dbutils.widgets.text('jdbc_config_file', '', '05 Source Table')\n",
    "dbutils.widgets.text('partition_col', '', '06 Source Partition Column')\n",
    "dbutils.widgets.text('partition_size_mb', '', '07 Partition Size MB')\n",
    "dbutils.widgets.text('tgt_catalog', '', '08 Target Catalog')\n",
    "dbutils.widgets.text('tgt_schema', '', '09 Target Schema')\n",
    "dbutils.widgets.text('tgt_table', '', '10 Target Table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45ab3641-09f0-476e-9c1b-1e69957ee78c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from lakefed_ingest.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2357b38e-5f3e-4477-b84d-776773c8bd0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "src_type = dbutils.widgets.get('src_type')\n",
    "src_catalog = dbutils.widgets.get('src_catalog')\n",
    "src_schema = dbutils.widgets.get('src_schema')\n",
    "src_table = dbutils.widgets.get('src_table')\n",
    "jdbc_config_file = dbutils.widgets.get('jdbc_config_file')\n",
    "partition_col = dbutils.widgets.get('partition_col')\n",
    "partition_size_mb = int(dbutils.widgets.get('partition_size_mb'))\n",
    "tgt_catalog = dbutils.widgets.get('tgt_catalog')\n",
    "tgt_schema = dbutils.widgets.get('tgt_schema')\n",
    "tgt_table = dbutils.widgets.get('tgt_table')\n",
    "\n",
    "jdbc_config_file = None if jdbc_config_file == '' else jdbc_config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad06769d-e2a5-4474-a3ab-e2c335539074",
     "showTitle": true,
     "title": "Get Source Table Size"
    }
   },
   "outputs": [],
   "source": [
    "table_size_mb = 0\n",
    "\n",
    "if src_type == 'sqlserver':\n",
    "    table_size_mb = get_table_size_sqlserver(src_catalog, src_schema, src_table)\n",
    "elif src_type == 'postgresql':\n",
    "    table_size_mb = get_table_size_postgresql(src_catalog, src_schema, src_table, jdbc_config_file=jdbc_config_file)\n",
    "elif src_type == 'delta':\n",
    "    table_size_mb = get_table_size_delta(src_catalog, src_schema, src_table)\n",
    "else:\n",
    "    raise ValueError(f'Unsupported src_type: {src_type}')\n",
    "\n",
    "print(f'Table size MB: {table_size_mb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fb7659b-e5da-4300-8b95-79de9654d39d",
     "showTitle": true,
     "title": "Get Partition Boundaries"
    }
   },
   "outputs": [],
   "source": [
    "lower_bound, upper_bound = get_partition_boundaries(src_catalog, src_schema, src_table, partition_col)\n",
    "\n",
    "print(f'Upper and lower bound: {lower_bound}, {upper_bound}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca88b99e-bed5-4f9b-a158-769d0627d2ca",
     "showTitle": true,
     "title": "Calculate Number of Partitions"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate number of partitions. Minimum is 2.\n",
    "num_partitions = int(table_size_mb / partition_size_mb)\n",
    "num_partitions = max(num_partitions, 2)\n",
    "\n",
    "print(f'Number of partitions: {num_partitions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f102639-3067-44bb-b66d-d1beb3f718be",
     "showTitle": true,
     "title": "Generate Partitions"
    }
   },
   "outputs": [],
   "source": [
    "# Generate partition list\n",
    "partition_list = get_partition_list(\n",
    "    partition_col,\n",
    "    lower_bound,\n",
    "    upper_bound,\n",
    "    num_partitions\n",
    ")\n",
    "\n",
    "# TODO set partitions table suffix at job level\n",
    "partitions_tbl = f'{tgt_catalog}.{tgt_schema}.{tgt_table}_partitions'\n",
    "\n",
    "# Write partitions to table\n",
    "partition_df = get_partition_df(partition_list, num_partitions)\n",
    "partition_df.write.option(\"overwriteSchema\", \"true\").mode(\"overwrite\").saveAsTable(partitions_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8aad25ce-35d6-4a1d-8366-1578bc1097b6",
     "showTitle": true,
     "title": "Get Batch List"
    }
   },
   "outputs": [],
   "source": [
    "# Get distinct list of batch_ids\n",
    "batch_list_qry = f\"\"\"\\\n",
    "    select array_agg(distinct batch_id) as batch_list\n",
    "    from {partitions_tbl}\n",
    "\"\"\"\n",
    "\n",
    "batch_list = spark.sql(batch_list_qry).collect()[0][0]\n",
    "batch_list.sort()\n",
    "print(f'batch_list: {batch_list}')\n",
    "\n",
    "# Assign batch list to job task value. The lvl1 job iterates over the batches.\n",
    "dbutils.jobs.taskValues.set(key=\"batch_list\", value=batch_list)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4165620575668529,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "get_partition_list",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
